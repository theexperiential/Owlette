"""
Firebase Client for Owlette 2.0

Handles all Firestore operations including:
- Machine presence/heartbeat
- Configuration sync with offline caching
- Command queue (bidirectional communication)
- System metrics reporting
- Offline resilience

OAuth Authentication:
This version uses custom token authentication via REST API instead of
service account credentials, eliminating the need for firebase-credentials.json.

Connection Management:
Uses centralized ConnectionManager for robust reconnection handling with:
- State machine (DISCONNECTED -> CONNECTING -> CONNECTED)
- Circuit breaker pattern
- Exponential backoff with jitter
- Thread supervision and watchdog
"""

import threading
import time
import json
import os
import logging
import socket
import hashlib
from typing import Dict, Any, Callable, Optional
from datetime import datetime

# Import shared utilities
import shared_utils
import registry_utils

# Import new OAuth-based modules (replace firebase_admin)
from auth_manager import AuthManager, AuthenticationError, TokenRefreshError
from firestore_rest_client import FirestoreRestClient, SERVER_TIMESTAMP, DELETE_FIELD

# Import centralized connection manager
from connection_manager import ConnectionManager, ConnectionState, ConnectionEvent


class FirebaseClient:
    """
    Main Firebase client for Owlette agent.
    Handles all cloud communication with offline resilience.

    Uses ConnectionManager for centralized connection state management,
    ensuring robust reconnection handling for all failure scenarios.
    """

    def __init__(self, auth_manager: AuthManager, project_id: str, site_id: str, config_cache_path: str = "config/firebase_cache.json"):
        """
        Initialize Firebase client with OAuth authentication.

        Args:
            auth_manager: AuthManager instance for token management
            project_id: Firebase project ID (e.g., "owlette-dev-3838a")
            site_id: Site ID this machine belongs to
            config_cache_path: Path to store cached config for offline mode
        """
        self.auth_manager = auth_manager
        self.project_id = project_id
        self.site_id = site_id
        self.machine_id = socket.gethostname()
        self.config_cache_path = config_cache_path

        # Firestore REST client instance
        self.db: Optional[FirestoreRestClient] = None

        # Logging
        self.logger = logging.getLogger("OwletteFirebase")

        # =================================================================
        # Connection Manager (centralized state management)
        # =================================================================
        self.connection_manager = ConnectionManager(self.logger)

        # Register callbacks with connection manager
        self.connection_manager.set_callbacks(
            connect=self._do_connect,
            disconnect=self._do_disconnect,
            on_connected=self._on_connected
        )

        # Register thread factories for supervision
        self.connection_manager.register_thread(
            "command_listener",
            self._create_command_listener_thread
        )
        self.connection_manager.register_thread(
            "config_listener",
            self._create_config_listener_thread
        )

        # Listen for state changes
        self.connection_manager.add_state_listener(self._on_connection_state_change)

        # =================================================================
        # Thread references (managed by ConnectionManager)
        # =================================================================
        self.metrics_thread: Optional[threading.Thread] = None
        self.running = False

        # =================================================================
        # Callbacks
        # =================================================================
        self.command_callback: Optional[Callable] = None
        self.config_update_callback: Optional[Callable] = None

        # =================================================================
        # Cached config for offline mode
        # =================================================================
        self.cached_config: Optional[Dict] = None

        # Track last uploaded config to prevent processing our own writes
        self._last_uploaded_config_hash: Optional[str] = None

        # Track last synced software inventory hash to prevent unnecessary writes
        self._last_software_inventory_hash: Optional[str] = None

        # =================================================================
        # Initialize Firebase connection
        # =================================================================
        self._load_cached_config()
        self.connection_manager.connect()

    # =========================================================================
    # Connection Manager Callbacks
    # =========================================================================

    def _do_connect(self) -> bool:
        """
        Called by ConnectionManager to establish connection.

        Returns:
            True if connection succeeded, False otherwise.
        """
        try:
            # Check if authenticated
            if not self.auth_manager.is_authenticated():
                self.logger.error("Agent not authenticated - no refresh token found")
                self.logger.warning("Running in OFFLINE MODE - will use cached config only")
                return False

            # Validate token before creating client
            try:
                self.auth_manager.get_valid_token()
            except (AuthenticationError, TokenRefreshError) as e:
                self.logger.error(f"Token validation failed: {e}")
                return False

            # Initialize Firestore REST client
            self.db = FirestoreRestClient(
                project_id=self.project_id,
                auth_manager=self.auth_manager
            )

            self.logger.info(f"Firestore initialized - Site: {self.site_id}, Machine: {self.machine_id}")
            return True

        except Exception as e:
            self.logger.error(f"Failed to initialize Firebase: {e}")
            return False

    def _do_disconnect(self):
        """
        Called by ConnectionManager during shutdown.
        Performs cleanup operations.
        """
        self.logger.debug("Disconnect callback: cleaning up resources")
        # Firestore REST client doesn't need explicit cleanup
        # but we could add cleanup here if needed

    def _on_connected(self):
        """
        Called by ConnectionManager after successful connection/reconnection.
        Performs initial data sync.
        """
        if not self.running:
            return  # Don't send data if not started

        try:
            # Send immediate heartbeat and metrics
            self._update_presence(True)
            self.logger.info("Heartbeat sent after connection")

            metrics = shared_utils.get_system_metrics()
            self._upload_metrics(metrics)
            self.logger.info("Initial metrics uploaded after connection")
        except Exception as e:
            self.logger.error(f"Failed to send initial data after connection: {e}")
            # Report error but don't fail - connection is still valid
            self.connection_manager.report_error(e, "Initial data upload")

    def _on_connection_state_change(self, event: ConnectionEvent):
        """
        React to connection state changes.

        Args:
            event: ConnectionEvent with old_state, new_state, reason
        """
        if event.new_state == ConnectionState.FATAL_ERROR:
            # Machine may have been removed from site
            self._handle_fatal_error(event.reason)

    def _handle_fatal_error(self, reason: str):
        """
        Handle fatal connection errors (e.g., machine removed from site).

        Args:
            reason: Reason for the fatal error
        """
        self.logger.error(f"Fatal connection error: {reason}")

        # Check if this looks like a removal
        reason_lower = reason.lower()
        if any(x in reason_lower for x in ['403', '404', 'permission', 'not found']):
            self.logger.warning("Machine may have been removed from site via web dashboard")
            self.logger.info("Disabling Firebase and clearing site_id in local config")

            try:
                # Load current config
                config = shared_utils.read_config()

                # Disable Firebase and clear site_id
                if 'firebase' not in config:
                    config['firebase'] = {}

                config['firebase']['enabled'] = False
                config['firebase']['site_id'] = ''

                # Save config
                shared_utils.save_config(config)
                self.logger.info("Local config updated - machine deregistered from site")

            except Exception as config_error:
                self.logger.error(f"Failed to update local config after removal detection: {config_error}")

    # =========================================================================
    # Thread Factories (for ConnectionManager supervision)
    # =========================================================================

    def _create_command_listener_thread(self) -> threading.Thread:
        """Factory for creating command listener thread."""
        return threading.Thread(target=self._command_listener_loop, daemon=True)

    def _create_config_listener_thread(self) -> threading.Thread:
        """Factory for creating config listener thread."""
        return threading.Thread(target=self._config_listener_loop, daemon=True)

    # =========================================================================
    # Public Properties
    # =========================================================================

    @property
    def connected(self) -> bool:
        """Check if connected to Firestore (via ConnectionManager)."""
        return self.connection_manager.is_connected

    def is_connected(self) -> bool:
        """Check if connected to Firestore."""
        return self.connection_manager.is_connected

    def get_machine_id(self) -> str:
        """Get the machine ID (hostname)."""
        return self.machine_id

    def get_site_id(self) -> str:
        """Get the site ID."""
        return self.site_id

    # =========================================================================
    # Lifecycle Methods
    # =========================================================================

    def start(self):
        """Start all background threads (metrics, command listener, config listener)."""
        if self.running:
            self.logger.warning("Firebase client already running")
            return

        self.running = True

        # Start watchdog for thread supervision
        self.connection_manager.start_watchdog()

        # Send immediate heartbeat and metrics if connected
        if self.connected:
            try:
                self._update_presence(True)
                self.logger.info("Initial heartbeat sent - machine is now online")

                metrics = shared_utils.get_system_metrics()
                self._upload_metrics(metrics)
                self.logger.info("Initial metrics uploaded")

                # Report success to reset any failure counters
                self.connection_manager.report_success()
            except Exception as e:
                self.logger.error(f"Failed to send initial heartbeat/metrics: {e}")
                self.connection_manager.report_error(e, "Initial heartbeat/metrics")

        self.logger.info("Heartbeat thread DISABLED - heartbeat data included in metrics")

        # Start metrics thread (main loop with reconnection logic)
        self.metrics_thread = threading.Thread(target=self._metrics_loop, daemon=True)
        self.metrics_thread.start()
        self.logger.info("Metrics thread started")

        # Start listeners if connected (ConnectionManager will supervise these)
        if self.connected:
            # Trigger initial thread start via connection manager
            self.connection_manager._restart_all_threads()
            self.logger.info("Listener threads started (supervised by ConnectionManager)")

            # Sync software inventory once on startup
            try:
                self._sync_software_inventory(force=True)
                self.logger.info("Initial software inventory synced to Firestore")
            except Exception as e:
                self.logger.error(f"Failed to sync initial software inventory: {e}")
        else:
            self.logger.warning("Listener threads NOT started (offline mode)")
            self.logger.warning("Software inventory NOT synced (offline mode)")

    def stop(self):
        """Stop all background threads and set machine offline."""
        self.logger.info("Stopping Firebase client and setting machine offline...")

        # Set machine as offline BEFORE stopping threads (critical for clean shutdown)
        if self.connected and self.db:
            try:
                presence_ref = self.db.collection('sites').document(self.site_id)\
                    .collection('machines').document(self.machine_id)

                max_attempts = 3
                for attempt in range(max_attempts):
                    try:
                        presence_ref.set({
                            'online': False,
                            'lastHeartbeat': SERVER_TIMESTAMP,
                            'machineId': self.machine_id,
                            'siteId': self.site_id
                        }, merge=True)
                        self.logger.info(f"[OK] Machine marked OFFLINE in Firestore (attempt {attempt + 1}/{max_attempts})")
                        time.sleep(1)
                        break
                    except Exception as e:
                        if attempt == max_attempts - 1:
                            raise
                        self.logger.warning(f"Offline update attempt {attempt + 1} failed, retrying...")
                        time.sleep(0.2)

            except Exception as e:
                self.logger.error(f"[ERROR] Failed to set machine offline after {max_attempts} attempts: {e}")

        # Stop the background threads
        self.running = False

        # Shutdown connection manager (stops watchdog and supervised threads)
        self.connection_manager.shutdown()

        self.logger.info("Background threads stopped")

    # =========================================================================
    # Main Metrics Loop
    # =========================================================================

    def _metrics_loop(self):
        """
        Metrics loop - uploads system stats with intelligent adaptive intervals.

        This is the main loop that also handles reconnection via ConnectionManager.

        Intervals:
        - 5s when GUI is open (user actively monitoring)
        - 30s when processes are running (active monitoring)
        - 120s when idle (minimal overhead)
        """
        self.logger.info("[THREAD] Metrics loop started")

        try:
            while self.running:
                interval = 60  # Default interval

                try:
                    if self.connected:
                        # Validate token before upload (may trigger refresh)
                        try:
                            self.auth_manager.get_valid_token()
                        except Exception as e:
                            self.logger.error(f"Token validation/refresh failed: {e}")
                            self.connection_manager.report_error(e, "Token validation")
                            time.sleep(60)
                            continue

                        # Upload metrics
                        metrics = shared_utils.get_system_metrics()
                        self._upload_metrics(metrics)

                        # Report success to connection manager
                        self.connection_manager.report_success()

                        # Adaptive interval based on activity
                        gui_running = shared_utils.is_script_running('owlette_gui.py')

                        if gui_running:
                            interval = 5
                            mode = 'GUI active'
                        else:
                            processes = metrics.get('processes', {})
                            any_process_running = any(
                                proc.get('status') == 'RUNNING'
                                for proc in processes.values()
                                if isinstance(proc, dict)
                            )

                            if any_process_running:
                                interval = 30
                                mode = 'processes active'
                            else:
                                interval = 120
                                mode = 'idle'

                        self.logger.info(f"Metrics uploaded - next in {interval}s ({mode})")

                    else:
                        # NOT CONNECTED - actively trigger reconnection attempt
                        state = self.connection_manager.state
                        reason = self.connection_manager.state_reason
                        self.logger.info(f"[METRICS] Not connected (state={state.name}): {reason}")

                        # Trigger reconnection if not already in progress
                        if state == ConnectionState.DISCONNECTED:
                            self.logger.info("[METRICS] Triggering reconnection attempt...")
                            self.connection_manager.force_reconnect("Metrics loop detected disconnect")

                        # Use shorter interval when disconnected
                        interval = 30

                except Exception as e:
                    self.logger.error(f"Metrics upload failed: {e}")
                    self.connection_manager.report_error(e, "Metrics upload")
                    interval = 60

                time.sleep(interval)

        except Exception as e:
            self.logger.error(f"[THREAD] Metrics loop CRASHED with unexpected error: {e}")
        finally:
            self.logger.error(f"[THREAD] Metrics loop EXITED (running={self.running})")

    # =========================================================================
    # Listener Loops
    # =========================================================================

    def _command_listener_loop(self):
        """Listen for commands from Firestore in real-time."""
        self.logger.info("[THREAD] Command listener loop started")

        if not self.connected:
            self.logger.warning("[THREAD] Command listener exiting - not connected")
            return

        try:
            commands_path = f"sites/{self.site_id}/machines/{self.machine_id}/commands/pending"

            def on_commands_changed(commands_data):
                """Handle commands document changes."""
                if commands_data:
                    for cmd_id, cmd_data in commands_data.items():
                        self._process_command(cmd_id, cmd_data)

            # Start listener (runs in separate thread, polls every 2 seconds)
            self.db.listen_to_document(commands_path, on_commands_changed)

            # Keep this thread alive while running and connected
            while self.running and self.connected:
                time.sleep(1)

        except Exception as e:
            self.logger.error(f"Command listener error: {e}")
            # Report error to connection manager for centralized handling
            self.connection_manager.report_error(e, "Command listener")
        finally:
            self.logger.info(f"[THREAD] Command listener loop EXITED (running={self.running}, connected={self.connected})")

    def _config_listener_loop(self):
        """Listen for config changes from Firestore in real-time."""
        self.logger.info("[THREAD] Config listener loop started")

        if not self.connected:
            self.logger.warning("[THREAD] Config listener exiting - not connected")
            return

        try:
            config_path = f"config/{self.site_id}/machines/{self.machine_id}"
            first_snapshot = True

            def on_config_changed(config_data):
                """Handle config document changes."""
                nonlocal first_snapshot

                if first_snapshot:
                    first_snapshot = False
                    self.logger.info("Config listener initialized (skipping initial snapshot)")
                    return

                if config_data:
                    incoming_hash = hashlib.md5(json.dumps(config_data, sort_keys=True).encode()).hexdigest()

                    if incoming_hash == self._last_uploaded_config_hash:
                        self.logger.debug(f"Skipping self-originated config change (hash: {incoming_hash[:8]}...)")
                        return

                    self.logger.info(f"Config change detected in Firestore (hash: {incoming_hash[:8]}...)")

                    self._save_cached_config(config_data)
                    self.cached_config = config_data

                    if self.config_update_callback:
                        try:
                            self.config_update_callback(config_data)
                        except Exception as e:
                            self.logger.error(f"Error in config update callback: {e}")
                            import traceback
                            self.logger.error(f"Traceback: {traceback.format_exc()}")
                    else:
                        self.logger.warning("No config update callback registered")

            # Start listener
            self.db.listen_to_document(config_path, on_config_changed)

            # Keep this thread alive while running and connected
            while self.running and self.connected:
                time.sleep(1)

        except Exception as e:
            self.logger.error(f"Config listener error: {e}")
            # Report error to connection manager for centralized handling
            self.connection_manager.report_error(e, "Config listener")
        finally:
            self.logger.info(f"[THREAD] Config listener loop EXITED (running={self.running}, connected={self.connected})")

    # =========================================================================
    # Firestore Operations
    # =========================================================================

    def _update_presence(self, online: bool):
        """Update machine presence/heartbeat in Firestore."""
        if not self.connected or not self.db:
            return

        try:
            presence_ref = self.db.collection('sites').document(self.site_id)\
                .collection('machines').document(self.machine_id)

            presence_ref.set({
                'online': online,
                'lastHeartbeat': SERVER_TIMESTAMP,
                'machineId': self.machine_id,
                'siteId': self.site_id
            }, merge=True)

            if online:
                self.logger.debug("Heartbeat: Machine online")
            else:
                self.logger.info(f"[OK] Machine marked OFFLINE in Firestore (site: {self.site_id}, machine: {self.machine_id})")

        except Exception as e:
            self.logger.error(f"Error updating presence: {e}")
            self.connection_manager.report_error(e, "Presence update")

    def _upload_metrics(self, metrics: Dict[str, Any]):
        """Upload system metrics to Firestore."""
        if not self.connected or not self.db:
            return

        metrics_ref = self.db.collection('sites').document(self.site_id)\
            .collection('machines').document(self.machine_id)

        try:
            processes_data = metrics.get('processes', {})
            self.logger.debug(f"Uploading metrics with {len(processes_data)} processes: {list(processes_data.keys())}")

            metrics_ref.set({
                'online': True,
                'lastHeartbeat': SERVER_TIMESTAMP,
                'agent_version': shared_utils.APP_VERSION,
                'machineId': self.machine_id,
                'siteId': self.site_id,
                'metrics': {
                    'cpu': metrics.get('cpu', {}),
                    'memory': metrics.get('memory', {}),
                    'disk': metrics.get('disk', {}),
                    'gpu': metrics.get('gpu', {}),
                    'timestamp': SERVER_TIMESTAMP,
                    'processes': processes_data
                }
            }, merge=True)

        except Exception as e:
            self.logger.error(f"Error uploading metrics: {e}")
            self.connection_manager.report_error(e, "Metrics upload")

    def _process_command(self, cmd_id: str, cmd_data: Dict[str, Any]):
        """Process a command received from Firestore."""
        try:
            cmd_type = cmd_data.get('type')
            self.logger.info(f"Processing command: {cmd_id} - Type: {cmd_type}")

            deployment_id = cmd_data.get('deployment_id')

            if self.command_callback:
                result = self.command_callback(cmd_id, cmd_data)

                is_error = isinstance(result, str) and result.startswith("Error:")

                if cmd_type == 'cancel_installation':
                    self._mark_command_cancelled(cmd_id, result, deployment_id, cmd_type)
                elif is_error:
                    self._mark_command_failed(cmd_id, result, deployment_id, cmd_type)
                else:
                    self._mark_command_completed(cmd_id, result, deployment_id, cmd_type)
            else:
                self.logger.warning(f"No command callback registered, ignoring command {cmd_id}")

        except Exception as e:
            self.logger.error(f"Error processing command {cmd_id}: {e}")
            self._mark_command_failed(cmd_id, str(e), cmd_data.get('deployment_id'), cmd_data.get('type'))

    def update_command_progress(self, cmd_id: str, status: str, deployment_id: Optional[str] = None, progress: Optional[int] = None):
        """
        Update command progress in Firestore (for intermediate states like downloading/installing).

        Args:
            cmd_id: Command ID
            status: Current status (e.g., 'downloading', 'installing')
            deployment_id: Optional deployment ID to track
            progress: Optional progress percentage (0-100)
        """
        if not self.connected or not self.db:
            return

        try:
            completed_ref = self.db.collection('sites').document(self.site_id)\
                .collection('machines').document(self.machine_id)\
                .collection('commands').document('completed')

            progress_data = {
                'status': status,
                'updatedAt': SERVER_TIMESTAMP
            }

            if deployment_id:
                progress_data['deployment_id'] = deployment_id

            if progress is not None:
                progress_data['progress'] = progress

            completed_ref.set({
                cmd_id: progress_data
            }, merge=True)

            self.logger.debug(f"Command {cmd_id} progress: {status}" + (f" ({progress}%)" if progress is not None else ""))

        except Exception as e:
            self.logger.error(f"Failed to update command {cmd_id} progress: {e}")

    def _mark_command_completed(self, cmd_id: str, result: Any, deployment_id: Optional[str] = None, cmd_type: Optional[str] = None):
        """Mark a command as completed in Firestore."""
        if not self.connected or not self.db:
            return

        try:
            pending_ref = self.db.collection('sites').document(self.site_id)\
                .collection('machines').document(self.machine_id)\
                .collection('commands').document('pending')

            pending_ref.update({
                cmd_id: DELETE_FIELD
            })

            completed_ref = self.db.collection('sites').document(self.site_id)\
                .collection('machines').document(self.machine_id)\
                .collection('commands').document('completed')

            completed_data = {
                'result': result,
                'status': 'completed',
                'completedAt': SERVER_TIMESTAMP
            }

            if deployment_id:
                completed_data['deployment_id'] = deployment_id

            if cmd_type:
                completed_data['type'] = cmd_type

            completed_ref.set({
                cmd_id: completed_data
            }, merge=True)

            self.logger.info(f"Command {cmd_id} marked as completed")

        except Exception as e:
            self.logger.error(f"Failed to mark command {cmd_id} as completed: {e}")

    def _mark_command_failed(self, cmd_id: str, error: str, deployment_id: Optional[str] = None, cmd_type: Optional[str] = None):
        """Mark a command as failed in Firestore."""
        if not self.connected or not self.db:
            return

        try:
            pending_ref = self.db.collection('sites').document(self.site_id)\
                .collection('machines').document(self.machine_id)\
                .collection('commands').document('pending')

            pending_ref.update({
                cmd_id: DELETE_FIELD
            })

            completed_ref = self.db.collection('sites').document(self.site_id)\
                .collection('machines').document(self.machine_id)\
                .collection('commands').document('completed')

            failed_data = {
                'error': error,
                'status': 'failed',
                'completedAt': SERVER_TIMESTAMP
            }

            if deployment_id:
                failed_data['deployment_id'] = deployment_id

            if cmd_type:
                failed_data['type'] = cmd_type

            completed_ref.set({
                cmd_id: failed_data
            }, merge=True)

            self.logger.error(f"Command {cmd_id} marked as failed: {error}")

        except Exception as e:
            self.logger.error(f"Failed to mark command {cmd_id} as failed: {e}")

    def _mark_command_cancelled(self, cmd_id: str, result: str, deployment_id: Optional[str] = None, cmd_type: Optional[str] = None):
        """Mark a command as cancelled in Firestore."""
        if not self.connected or not self.db:
            return

        try:
            pending_ref = self.db.collection('sites').document(self.site_id)\
                .collection('machines').document(self.machine_id)\
                .collection('commands').document('pending')

            pending_ref.update({
                cmd_id: DELETE_FIELD
            })

            completed_ref = self.db.collection('sites').document(self.site_id)\
                .collection('machines').document(self.machine_id)\
                .collection('commands').document('completed')

            cancelled_data = {
                'result': result,
                'status': 'cancelled',
                'completedAt': SERVER_TIMESTAMP
            }

            if deployment_id:
                cancelled_data['deployment_id'] = deployment_id

            if cmd_type:
                cancelled_data['type'] = cmd_type

            completed_ref.set({
                cmd_id: cancelled_data
            }, merge=True)

            self.logger.info(f"Command {cmd_id} marked as cancelled")

        except Exception as e:
            self.logger.error(f"Failed to mark command {cmd_id} as cancelled: {e}")

    # =========================================================================
    # Configuration
    # =========================================================================

    def get_config(self) -> Optional[Dict]:
        """
        Get machine configuration from Firestore (or cache if offline).

        Returns:
            Configuration dict or None if not available
        """
        if self.connected and self.db:
            try:
                config_ref = self.db.collection('config').document(self.site_id)\
                    .collection('machines').document(self.machine_id)

                doc = config_ref.get()
                if doc.exists:
                    config = doc.to_dict()
                    self._save_cached_config(config)
                    self.cached_config = config
                    return config
            except Exception as e:
                self.logger.error(f"Failed to get config from Firestore: {e}")
                self.connection_manager.report_error(e, "Get config")

        if self.cached_config:
            self.logger.info("Using cached config (offline mode)")
            return self.cached_config

        return None

    def upload_config(self, config: Dict):
        """
        Upload local config to Firestore.
        Used for initial migration from local config.json.

        Args:
            config: Configuration dict to upload
        """
        if not self.connected or not self.db:
            self.logger.warning("Cannot upload config - not connected to Firestore")
            return

        try:
            config_ref = self.db.collection('config').document(self.site_id)\
                .collection('machines').document(self.machine_id)

            config_ref.set(config, merge=True)

            config_hash = hashlib.md5(json.dumps(config, sort_keys=True).encode()).hexdigest()
            self._last_uploaded_config_hash = config_hash

            self.logger.info(f"Config uploaded to Firestore successfully (hash: {config_hash[:8]}...)")

            self._save_cached_config(config)
            self.cached_config = config

        except Exception as e:
            self.logger.error(f"Failed to upload config to Firestore: {e}")
            self.connection_manager.report_error(e, "Upload config")

    def _load_cached_config(self):
        """Load cached config from disk."""
        try:
            if os.path.exists(self.config_cache_path):
                with open(self.config_cache_path, 'r') as f:
                    self.cached_config = json.load(f)
                self.logger.info(f"Loaded cached config from {self.config_cache_path}")
        except Exception as e:
            self.logger.error(f"Failed to load cached config: {e}")

    def _save_cached_config(self, config: Dict):
        """Save config to disk cache."""
        try:
            os.makedirs(os.path.dirname(self.config_cache_path), exist_ok=True)
            with open(self.config_cache_path, 'w') as f:
                json.dump(config, f, indent=2)
            self.logger.debug("Config cached to disk")
        except Exception as e:
            self.logger.error(f"Failed to save cached config: {e}")

    # =========================================================================
    # Callback Registration
    # =========================================================================

    def register_command_callback(self, callback: Callable):
        """
        Register a callback function to handle commands.

        Args:
            callback: Function that takes (cmd_id, cmd_data) and returns result
        """
        self.command_callback = callback
        self.logger.info("Command callback registered")

    def register_config_update_callback(self, callback: Callable):
        """
        Register a callback function to handle config updates.

        Args:
            callback: Function that takes (config) and handles the update
        """
        self.config_update_callback = callback
        self.logger.info("Config update callback registered")

    # =========================================================================
    # Event Logging
    # =========================================================================

    def log_event(self, action: str, level: str, process_name: str = None, details: str = None, user_id: str = None):
        """
        Log a process event to Firestore for dashboard monitoring.
        Non-blocking - failures are silently ignored to prevent logging from crashing the app.

        Args:
            action: Event action (process_start, process_killed, process_crash, command_executed, etc.)
            level: Log level (info, warning, error)
            process_name: Name of the process involved (optional)
            details: Additional details about the event (optional)
            user_id: User ID if action was triggered by a user (optional)
        """
        if not self.connected or not self.db:
            return

        try:
            logs_ref = self.db.collection('sites').document(self.site_id)\
                .collection('logs')

            event_data = {
                'timestamp': SERVER_TIMESTAMP,
                'action': action,
                'level': level,
                'machineId': self.machine_id,
                'machineName': self.machine_id,
            }

            if process_name:
                event_data['processName'] = process_name
            if details:
                event_data['details'] = details
            if user_id:
                event_data['userId'] = user_id

            import uuid
            doc_id = str(uuid.uuid4())
            doc_ref = logs_ref.document(doc_id)
            doc_ref.set(event_data)

            self.logger.info(f"[EVENT LOGGED] {action} - {process_name} ({level})")

        except Exception as e:
            self.logger.info(f"[EVENT LOG FAILED] {action}: {e}")

    def ship_logs(self, log_entries: list):
        """
        Ship log entries to Firestore for centralized monitoring.
        Non-blocking - failures are silently ignored to prevent logging from crashing the app.

        Args:
            log_entries: List of log entry dicts with keys: timestamp, level, message, logger, filename, line
        """
        if not self.connected or not self.db:
            return

        try:
            batch = self.db.batch()

            logs_ref = self.db.collection('sites').document(self.site_id)\
                .collection('machines').document(self.machine_id)\
                .collection('logs')

            for log_entry in log_entries:
                log_entry['server_timestamp'] = SERVER_TIMESTAMP
                log_entry['machine_id'] = self.machine_id
                log_entry['site_id'] = self.site_id

                doc_ref = logs_ref.document()
                batch.set(doc_ref, log_entry)

            batch.commit()
            self.logger.debug(f"Shipped {len(log_entries)} log entries to Firebase")

        except Exception as e:
            pass  # Silently fail

    # =========================================================================
    # Software Inventory
    # =========================================================================

    def sync_software_inventory(self):
        """
        Manually trigger software inventory sync (public API).

        Call this after software deployments to refresh the inventory.
        Non-blocking - failures are logged but don't raise exceptions.
        """
        try:
            self._sync_software_inventory(force=True)
            self.logger.info("Software inventory synced on-demand")
        except Exception as e:
            self.logger.error(f"On-demand software inventory sync failed: {e}")

    def _calculate_software_hash(self, software_list):
        """
        Calculate a hash of the software list to detect changes.

        Args:
            software_list: List of software dictionaries

        Returns:
            MD5 hash string of the software list
        """
        sorted_software = sorted(software_list, key=lambda s: (s.get('name', ''), s.get('version', '')))

        software_str = '|'.join([
            f"{s.get('name', '')}:{s.get('version', '')}"
            for s in sorted_software
        ])

        return hashlib.md5(software_str.encode('utf-8')).hexdigest()

    def _sync_software_inventory(self, force=False):
        """
        Sync installed software to Firestore.

        Queries Windows registry for installed software and uploads to:
        sites/{site_id}/machines/{machine_id}/installed_software

        Args:
            force: If True, sync even if software hasn't changed (for on-demand refresh)
        """
        if not self.connected or not self.db:
            return

        try:
            installed_software = registry_utils.get_installed_software()

            if not installed_software:
                self.logger.debug("No installed software detected")
                return

            current_hash = self._calculate_software_hash(installed_software)

            if not force and current_hash == self._last_software_inventory_hash:
                self.logger.debug("Software inventory unchanged, skipping sync")
                return

            software_collection_ref = self.db.collection('sites').document(self.site_id)\
                .collection('machines').document(self.machine_id)\
                .collection('installed_software')

            try:
                existing_docs = software_collection_ref.stream()
                for doc in existing_docs:
                    doc.reference.delete()
            except Exception as e:
                self.logger.warning(f"Failed to clear existing software inventory: {e}")

            batch_write_failed = False

            try:
                batch = self.db.batch()
                batch_count = 0

                for software in installed_software:
                    doc_id = f"{software['name']}_{software['version']}".replace('/', '_').replace('\\', '_')
                    doc_id = doc_id[:1500]

                    doc_ref = software_collection_ref.document(doc_id)

                    software_data = {
                        **software,
                        'detected_at': SERVER_TIMESTAMP
                    }

                    batch.set(doc_ref, software_data)
                    batch_count += 1

                    if batch_count >= 500:
                        batch.commit()
                        batch = self.db.batch()
                        batch_count = 0

                if batch_count > 0:
                    batch.commit()

                self.logger.info(f"Synced {len(installed_software)} software packages to Firestore (batch write)")
                self._last_software_inventory_hash = current_hash

            except Exception as batch_error:
                self.logger.info(f"Batch write not available (using individual writes instead)")
                self.logger.debug(f"Batch write error: {batch_error}")
                batch_write_failed = True

            if batch_write_failed:
                success_count = 0
                for software in installed_software:
                    try:
                        doc_id = f"{software['name']}_{software['version']}".replace('/', '_').replace('\\', '_')
                        doc_id = doc_id[:1500]

                        doc_ref = software_collection_ref.document(doc_id)
                        software_data = {
                            **software,
                            'detected_at': SERVER_TIMESTAMP
                        }
                        doc_ref.set(software_data)
                        success_count += 1
                    except Exception as write_error:
                        self.logger.warning(f"Failed to write {software.get('name', 'unknown')}: {write_error}")

                self.logger.info(f"Synced {success_count}/{len(installed_software)} software packages (individual writes)")
                if success_count > 0:
                    self._last_software_inventory_hash = current_hash

        except Exception as e:
            self.logger.error(f"Failed to sync software inventory: {e}")
            self.logger.exception("Software inventory sync error details:")
            self.connection_manager.report_error(e, "Software inventory sync")


# Example usage / testing
if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # Initialize client (requires auth_manager)
    from auth_manager import AuthManager
    auth_manager = AuthManager(api_base="https://owlette.app/api")

    client = FirebaseClient(
        auth_manager=auth_manager,
        project_id="owlette-dev-3838a",
        site_id="test_site_001"
    )

    def handle_command(cmd_id, cmd_data):
        cmd_type = cmd_data.get('type')
        print(f"Received command: {cmd_type}")

        if cmd_type == 'restart_process':
            process_name = cmd_data.get('process_name')
            print(f"Restarting process: {process_name}")
            return f"Process {process_name} restarted"

        elif cmd_type == 'kill_process':
            process_name = cmd_data.get('process_name')
            print(f"Killing process: {process_name}")
            return f"Process {process_name} killed"

        return "Command executed"

    client.register_command_callback(handle_command)
    client.start()

    test_config = {
        "version": "2.0.3",
        "processes": [
            {
                "name": "TouchDesigner",
                "exe_path": "C:\\TouchDesigner\\bin\\TouchDesigner.exe"
            }
        ]
    }
    client.upload_config(test_config)

    try:
        print("Firebase client running... Press Ctrl+C to stop")
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\nStopping...")
        client.stop()
